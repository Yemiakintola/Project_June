# -*- coding: utf-8 -*-
"""crop_predictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j3kh5gvYQoJOASgz1Hhvyt7MJKYd33nI

machine learning models to predict crop to be planted provided with other features like Average_Rainfall, Average_Temperature, Average_Soil_pH, Planting_Season and Soil_Texture
"""

import os
os.environ["OMP_NUM_THREADS"] = "1"

    # Now import sklearn and other libraries
from sklearn.cluster import KMeans
import pandas as pd
    # ... rest of your code

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("average_weather.csv")
df

df.info()
df.describe()
df.size
print(df.columns)

df.columns = df.columns.str.strip()

import matplotlib.pyplot as plt
import seaborn as sns

# 1. Data Types and Missing Values
print("Data Types and Missing Values:")
print(df.info())

# 2. Descriptive Statistics
print("\nDescriptive Statistics for Numerical Features:")
numerical_features = ['Average_Rainfall', 'Average_Temperature', 'Average_Soil_pH']
print(df[numerical_features].describe())


# 3. Distributions of Features
plt.figure(figsize=(15, 10))

plt.subplot(2, 2, 1)
plt.hist(df['Average_Rainfall'], bins=10, color='skyblue', edgecolor='black')
plt.title('Distribution of Average Rainfall')
plt.xlabel('Average Rainfall')
plt.ylabel('Frequency')

plt.subplot(2, 2, 2)
plt.hist(df['Average_Temperature'], bins=10, color='salmon', edgecolor='black')
plt.title('Distribution of Average Temperature')
plt.xlabel('Average Temperature')
plt.ylabel('Frequency')

plt.subplot(2, 2, 3)
plt.hist(df['Average_Soil_pH'], bins=10, color='lightgreen', edgecolor='black')
plt.title('Distribution of Average Soil pH')
plt.xlabel('Average Soil pH')
plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

for col in ['Planting_Season', 'Soil_Texture']:
    plt.figure(figsize=(8, 6))
    df[col].value_counts().plot(kind='bar', color='orange')
    plt.title(f'Frequency of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.show()


# 4. Correlation Analysis
plt.figure(figsize=(8, 6))
correlation_matrix = df[numerical_features].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of Numerical Features')
plt.show()

# 5. Unique Crop Types
print("\nUnique Crop Types and Frequencies:")
crop_counts = df['Crop'].value_counts()
print(crop_counts)

"""Group similar crops based on numerical features using KMeans clustering, then replace the 'Crop' column with cluster labels and check the distribution of the new labels."""

# Commented out IPython magic to ensure Python compatibility.
# %env OMP_NUM_THREADS=1

import os
os.environ["OMP_NUM_THREADS"] = "1" # Redundant but can help ensure it's set

# Now, import other libraries and run your code
import pandas as pd
from sklearn.cluster import KMeans
# ... rest of your code
import os
os.environ["OMP_NUM_THREADS"] = "1"
from sklearn.cluster import KMeans
import numpy as np

# Select numerical features for clustering
features = ['Average_Rainfall', 'Average_Temperature', 'Average_Soil_pH']
X = df[features]

# Determine the optimal number of clusters (e.g., using the elbow method or silhouette analysis)
# For simplicity, let's choose 10 clusters here.  A more robust approach would be to use the elbow method or silhouette analysis.
n_clusters = 10

# Apply KMeans clustering
kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)  # Set random_state for reproducibility
df['Cluster'] = kmeans.fit_predict(X)

# Replace the 'Crop' column with the cluster labels
df= df.drop('Crop', axis=1)

# Verify cluster distribution
cluster_counts = df['Cluster'].value_counts()
print("Cluster Distribution:\n", cluster_counts)

# Check for clusters with very few samples
min_samples_per_cluster = 5  # Define the minimum acceptable number of samples per cluster
small_clusters = cluster_counts[cluster_counts < min_samples_per_cluster].index
print(f"\nClusters with fewer than {min_samples_per_cluster} samples: {small_clusters}")

# If there are small clusters, consider merging them or adjusting the number of clusters.
# This would require additional steps (e.g., hierarchical clustering or merging based on similarity)
# For now, we will proceed with the current clustering result.

# Check data types
print(df.dtypes)

# Convert categorical features to appropriate types (if necessary)
for col in ['Soil_Texture', 'Planting_Season']:
    if df[col].dtype != 'object':
        df[col] = df[col].astype('object')

# Check for and handle any remaining inconsistencies or errors (if any)
# (No obvious inconsistencies found in the initial exploration)

# Display the updated dataframe
display(df.head())

import matplotlib.pyplot as plt
import seaborn as sns

# Box plots of numerical features grouped by cluster
plt.figure(figsize=(15, 5))
for i, col in enumerate(['Average_Rainfall', 'Average_Temperature', 'Average_Soil_pH']):
    plt.subplot(1, 3, i + 1)
    sns.boxplot(x='Cluster', y=col, data=df, palette='Set3', hue='Cluster', legend=False) # Fixed palette usage
    plt.title(f'{col} by Cluster')
plt.tight_layout()
plt.show()

# Scatter plots of numerical feature pairs colored by cluster
sns.pairplot(df, vars=['Average_Rainfall', 'Average_Temperature', 'Average_Soil_pH'], hue='Cluster', palette='Set1')
plt.show()


# Count plots for categorical features colored by cluster
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
sns.countplot(x='Planting_Season', hue='Cluster', data=df, palette='viridis')
plt.title('Planting Season by Cluster')
plt.xticks(rotation=45, ha='right')

plt.subplot(1, 2, 2)
sns.countplot(x='Soil_Texture', hue='Cluster', data=df, palette='magma')
plt.title('Soil Texture by Cluster')
plt.xticks(rotation=45, ha='right')

plt.tight_layout()
plt.show()

import pandas as pd
from sklearn.preprocessing import StandardScaler

# One-hot encode categorical features
categorical_cols = ['Soil_Texture', 'Planting_Season']
df_encoded = pd.get_dummies(df, columns=categorical_cols, dummy_na=True)

# Scale numerical features
numerical_cols = ['Average_Rainfall', 'Average_Temperature', 'Average_Soil_pH']
scaler = StandardScaler()
df_encoded[numerical_cols] = scaler.fit_transform(df_encoded[numerical_cols])

# Combine features into df_processed
df_processed = df_encoded

display(df_processed.head())

from sklearn.model_selection import train_test_split

# Define features (X) and target (y)
X = df_processed.drop('Cluster', axis=1)
y = df_processed['Cluster']

# Split data into training (70%) and a temporary set (30%)
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# Split the temporary set into validation (15%) and test (15%)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
)

# Print the shapes of the resulting sets to verify the split
print("X_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)
print("X_val shape:", X_val.shape)
print("y_val shape:", y_val.shape)
print("X_test shape:", X_test.shape)
print("y_test shape:", y_test.shape)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report

# Instantiate models
logreg_model = LogisticRegression(max_iter=1000) # Increased max_iter to avoid convergence warnings
rf_model = RandomForestClassifier(random_state=42)
svm_model = SVC(random_state=42)
gbm_model = GradientBoostingClassifier(random_state=42)
knn_model = KNeighborsClassifier()

# Train models
logreg_model.fit(X_train, y_train)
rf_model.fit(X_train, y_train)
svm_model.fit(X_train, y_train)
gbm_model.fit(X_train, y_train)
knn_model.fit(X_train, y_train)

# Store trained models (in this case, they're already in memory)
trained_models = {
    'Logistic Regression': logreg_model,
    'Random Forest': rf_model,
    'SVM': svm_model,
    'GBM': gbm_model,
    'k-NN': knn_model
}

import pickle

# Assuming 'best_models' is the dictionary containing your trained models
# And 'k-NN' is the key for the k-NN model in that dictionary
knn_model = best_models['k-NN']

# Define the filename for the saved model
filename = 'knn_model.pkl'

# Save the model to a .pkl file
with open(filename, 'wb') as f:
    pickle.dump(knn_model, f)

print(f"k-NN model saved successfully to {filename}")

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, f1_score

# Define parameter grids for each model, excluding 'l1' penalty for Logistic Regression
param_grids = {
    'Logistic Regression': {'C': [0.1, 1, 10], 'penalty': ['l2']},  # Removed 'l1'
    'Random Forest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]},
    'SVM': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': [0.1, 1, 10]},
    'GBM': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1], 'max_depth': [3, 5, 7]},
    'k-NN': {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}
}

best_models = {}
for model_name, model in trained_models.items():
    grid_search = GridSearchCV(model, param_grids[model_name], cv=2, scoring='accuracy', error_score='raise')
    grid_search.fit(X_val, y_val)
    best_models[model_name] = grid_search.best_estimator_
    print(f"Best hyperparameters for {model_name}: {grid_search.best_params_}")
    print(f"Best accuracy score for {model_name}: {grid_search.best_score_}")

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

for model_name, model in best_models.items():
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Model: {model_name}")
    print(f"Accuracy: {accuracy}")

    try:
        precision = precision_score(y_test, y_pred, average='weighted')
        recall = recall_score(y_test, y_pred, average='weighted')
        f1 = f1_score(y_test, y_pred, average='weighted')
        print(f"Precision: {precision}")
        print(f"Recall: {recall}")
        print(f"F1-score: {f1}")
    except Exception as e:
        print(f"Error calculating precision, recall, or F1-score: {e}")

    try:
        # Confusion matrix
        cm = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
        plt.title(f"Confusion Matrix for {model_name}")
        plt.xlabel("Predicted")
        plt.ylabel("True")
        plt.show()
    except Exception as e:
        print(f"Error creating confusion matrix: {e}")

    print(classification_report(y_test, y_pred))

    try:
        # ROC AUC (requires probabilities)
        y_prob = model.predict_proba(X_test)
        roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr')
        print(f"ROC AUC score: {roc_auc}")
    except Exception as e:
        print(f"Error calculating ROC AUC score: {e}")

# Robustness Check
print("\nRobustness Check")
for model_name, model in best_models.items():
    print(f"\nModel: {model_name}")
    # Introduce small variations to the test set
    X_test_perturbed = X_test.copy()
    for col in ['Average_Rainfall', 'Average_Temperature', 'Average_Soil_pH']:
      X_test_perturbed[col] = X_test_perturbed[col] + np.random.normal(0, 0.1, len(X_test))
    y_pred_perturbed = model.predict(X_test_perturbed)
    accuracy_perturbed = accuracy_score(y_test, y_pred_perturbed)
    print(f"Accuracy after perturbation: {accuracy_perturbed}")

    diff = accuracy - accuracy_perturbed
    print(f"Accuracy difference: {diff}")